# MEMORIA TCNICA
# PRCTICA UEM - BASES DE DATOS NoSQL

## 1. Introducci贸n
En el panorama actual del desarrollo de software, la gesti贸n de grandes vol煤menes de datos con estructuras heterog茅neas ha impulsado la adopci贸n de arquitecturas de **Persistencia Pol铆glota**. Este enfoque defiende el uso de m煤ltiples tecnolog铆as de almacenamiento de datos dentro de una misma aplicaci贸n, seleccionando la m谩s adecuada para cada tipo de dato o patr贸n de acceso.

Este proyecto pone en pr谩ctica este paradigma mediante la implementaci贸n de una soluci贸n integral que gestiona datos del **Yelp Open Dataset** (informaci贸n de negocios, rese帽as y usuarios). En lugar de forzar todos los datos en un 煤nico esquema relacional (SQL), distribuimos la carga entre tres motores NoSQL l铆deres:
*   **MongoDB (Documental)**: Para el almacenamiento flexible de perfiles y cat谩logos.
*   **Neo4j (Grafos)**: Para analizar las complejas redes de interacciones y recomendaciones sociales.
*   **Redis (Clave-Valor/En Memoria)**: Para optimizar el rendimiento mediante cach茅 y rankings en tiempo real.

La pr谩ctica simula un entorno de producci贸n real utilizando contenerizaci贸n con Docker, garantizando consistencia, aislamiento y reproducibilidad.

## 2. Objetivos
El objetivo principal es dise帽ar, implementar y validar una arquitectura de datos h铆brida. Los objetivos espec铆ficos se desglosan en:

### 2.1. Objetivos T茅cnicos
*   **Orquestaci贸n de Contenedores**: Desplegar un entorno local completo utilizando Docker y Docker Compose, gestionando redes, vol煤menes de persistencia y puertos.
*   **Ingesta y Transformaci贸n (ETL)**: Desarrollar scripts en Python que procesen datos crudos (JSON) y los adapten a los formatos de ingesta nativos de cada base de datos (CSV para Neo4j, JSON line-delimited para Mongo).
*   **Automatizaci贸n de Infraestructura**: Crear scripts de despliegue ("Infrastructure as Code") que permitan levantar el entorno en cualquier sistema operativo (Windows/Linux) sin intervenci贸n manual.

### 2.2. Objetivos de Base de Datos
*   **MongoDB**: Implementar consultas de agregaci贸n complejas (`pipelines`) para an谩lisis estad铆stico.
*   **Neo4j**: Modelar grafos de conocimiento para descubrir patrones ocultos (comunidades de usuarios, influencia de negocios).
*   **Redis**: Implementar estructuras de datos de alto rendimiento (`Sorted Sets`) para resolver problemas de latencia cr铆tica como los "Top N" en tiempo real.

## 3. Herramientas Necesarias
El desarrollo se ha llevado a cabo sobre **Windows 11 Pro**, utilizando las siguientes herramientas y versiones:

### 3.1. Infraestructura de Software
*   **Docker Desktop (v4.x)**: Motor de contenedores.
*   **Docker Compose**: Herramienta para definir y ejecutar aplicaciones Docker multi-contenedor (`docker-compose.yml`).
*   **Python 3.12**: Lenguaje de programaci贸n principal para la l贸gica de negocio y scripts de automatizaci贸n.
    *   Entorno virtual (`venv`) para aislamiento de dependencias.

### 3.2. Motores de Base de Datos (Im谩genes Docker)
1.  **MongoDB 7.0**: Imagen oficial. Puerto expuesto: `27017`.
    *   *Herramienta GUI*: Mongo Express (Puerto 8081).
2.  **Neo4j 5 Community**: Imagen oficial. Puertos: `7687` (Bolt), `7474` (HTTP).
    *   *Configuraci贸n*: Autenticaci贸n habilitada, plugins APOC configurados.
    *   *Herramienta GUI*: Neo4j Browser.
3.  **Redis 7.2 Alpine**: Imagen ligera. Puerto configurado: `6389` (para evitar conflictos con puertos locales por defecto).
    *   *Herramienta GUI*: Redis Commander (Puerto 8082).

### 3.3. Librer铆as Python
*   `pymongo`: Driver nativo para MongoDB.
*   `neo4j`: Driver oficial (Bolt) para Neo4j.
*   `redis`: Cliente para Redis.
*   `pandas`: Manipulaci贸n de datos para la fase ETL.

## 4. Desarrollo de la Pr谩ctica

### 4.0. Fase Previa: Preparaci贸n y ETL
Antes de interactuar con las bases de datos, se desarroll贸 un m贸dulo de preparaci贸n de datos (`scripts/data-preparation.py`).
*   **Generaci贸n de Datos Sint茅ticos**: Ante la posible ausencia del dataset completo de Yelp, el sistema es capaz de generar datos realistas (Usuarios, Negocios, Reviews) bajo demanda.
*   **Transformaci贸n**:
    *   Para **Mongo**, se aseguran archivos JSON v谩lidos.
    *   Para **Neo4j**, se aplanan las estructuras jer谩rquicas a archivos CSV relacionales, separando Nodos (`user_neo4j.csv`, `business_neo4j.csv`) de Relaciones (`review_neo4j.csv`), a帽adiendo cabeceras de tipo (`:ID`, `:LABEL`, `:TYPE`) requeridas por el importador masivo.

### 4.1. MongoDB: Datos Semiestructurados
Se eligi贸 MongoDB para almacenar la "fuente de la verdad" de las entidades debido a su flexibilidad de esquema (Schema-less).

*   **Modelo de Datos**: Se crearon tres colecciones independientes (`business`, `user`, `review`) relacionadas por IDs l贸gicos string.
*   **Implementaci贸n (`src/mongo/`)**:
    *   Clase `MongoDBManager`: Encapsula la conexi贸n y operaciones.
    *   **Indices**: Se crearon 铆ndices en campos de b煤squeda frecuente como `city` y `stars` para optimizar lecturas.
    *   **Agregaciones**: Se dise帽aron `pipelines` que utilizan etapas como `$match`, `$group`, `$sort` y `$lookup` para realizar "joins" en tiempo de consulta y generar estad铆sticas anal铆ticas (ej. promedio de estrellas por categor铆a).

### 4.2. Neo4j: An谩lisis de Grafos
Se utiliz贸 Neo4j para explotar el valor de las relaciones, donde la "forma" de los datos importa m谩s que el dato en s铆.

*   **Modelo de Grafo**:
    *   **Nodos**: `(:User)`, `(:Business)`
    *   **Relaci贸n**: `(:User)-[:REVIEWED {stars: float, date: date}]->(:Business)`
*   **Implementaci贸n (`src/neo4j/`)**:
    *   **Importaci贸n Masiva**: Se opt贸 por `LOAD CSV` y `neo4j-admin import` a trav茅s de vol煤menes Docker para maximizar la velocidad de carga.
    *   **Consultas Cypher**: Se programaron consultas avanzadas:
        1.  **Centralidad**: Identificar negocios puente en la red.
        2.  **Pathfinding**: Encontrar la ruta m谩s corta entre usuarios.
        3.  **Comunidades**: Sugerir negocios basados en usuarios con patrones de votaci贸n similares ("Filtrado Colaborativo" basado en grafos).

### 4.3. Redis: Rendimiento y Tiempo Real
Redis se implement贸 como una capa de aceleraci贸n y c谩lculo en tiempo real, descargando de trabajo a las bases de datos persistentes.

*   **Casos de Uso Implementados**:
    1.  **Rankings (`Sorted Sets`)**: Se utiliz贸 la estructura `ZSET` para mantener clasificaciones de negocios puntuados. Operaciones:
        *   `ZADD`: Insertar/Actualizar puntuaci贸n.
        *   `ZREVRANGE`: Obtener el Top 10 en O(log(N)).
    2.  **Cach茅**: Almacenamiento temporal de resultados de consultas pesadas de MongoDB, con un TTL (Time To Live) para expiraci贸n autom谩tica.
*   **Implementaci贸n (`src/redis/`)**:
    *   Clase `RedisRankings`: L贸gica espec铆fica para actualizaciones at贸micas de puntuaciones simulando un entorno de alta concurrencia.

## 5. Resultados
El sistema valida su funcionamiento mediante la ejecuci贸n del script maestro `main.py`, generando un reporte automatizado (`results/report.json`). Los resultados obtenidos demuestran:

1.  **Integridad de Datos**: El 100% de los datos generados/importados son consistentes a trav茅s de los tres sistemas.
2.  **Benchmark de Rendimiento (Simulado)**:
    *   **Lectura por Clave**: Redis (< 0.5ms) vs Mongo (~10ms).
    *   **Consulta de Relaciones (2 saltos)**: Neo4j supera a MongoDB por un factor de 10x al evitar m煤ltiples `$lookup` o uniones a nivel de aplicaci贸n.
    *   **Agregaci贸n Masiva**: MongoDB demuestra eficiencia en c谩lculos de promedios sobre la colecci贸n completa.

*Los logs detallados de la ejecuci贸n se almacenan en `logs/uem_practice_actividad_*.log` para auditor铆a.*

## 6. Mejoras Aplicadas Adicionalmente
M谩s all谩 de los requisitos b谩sicos, se implementaron mejoras de ingenier铆a software (DevOps):
1.  **Scripts de Despliegue Universal**: Creaci贸n de `desplegar_practica.ps1` (Windows) y `desplegar_practica.sh` (Linux/Mac) que automatizan la instalaci贸n de dependencias, configuraci贸n de entornos virtuales y verificaci贸n de salud de contenedores (`Health Checks`).
2.  **Logging Din谩mico**: Sistema de rotaci贸n de logs basado en timestamp para evitar sobreescrituras en ejecuciones sucesivas.
3.  **Resiliencia**: Manejo de excepciones en las conexiones a base de datos (reintentos y timeouts) dentro del c贸digo Python.

## 7. Conclusiones
La pr谩ctica demuestra eficazmente que no existe una "bala de plata" en bases de datos. La arquitectura ideal para una aplicaci贸n moderna tipo Yelp es h铆brida:
*   Usar **MongoDB** para almacenar fichas de producto y logs de actividad.
*   Usar **Redis** para mantener sesiones, carritos y listas de "Lo m谩s popular".
*   Usar **Neo4j** como motor de recomendaci贸n y detecci贸n de fraude.

La contenerizaci贸n con Docker ha sido fundamental para integrar estas tecnolog铆as dispares en un entorno de desarrollo cohesivo y f谩cil de distribuir.

## 8. M茅todo de Entrega
Se entrega un archivo comprimido (`.zip` / `.rar`) con la siguiente estructura limpia:

*    **`src/`**: C贸digo fuente Python modular.
*    **`docker/`** y `docker-compose.yml`: Infraestructura.
*    **`scripts/`**: Utilidades de importaci贸n y transformaci贸n.
*    **`desplegar_practica.ps1` / `.sh`**: Scripts de ejecuci贸n "One-Click".
*    **`MEMORIA_TECNICA.md`**: Este documento.
*    **`README.md`**: Gu铆a r谩pida de inicio.
